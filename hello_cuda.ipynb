{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyORTEzw32hYMV/l3P5KtD6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romiebanerjee/cuda-examples/blob/master/hello_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljko19q8zfLu",
        "outputId": "ba087ee0-b7a6-425a-d0f3-cbcd56437afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h> // Needed for CUDA functions and types\n",
        "\n",
        "// 1. KERNEL DEFINITION\n",
        "// This function will execute on the GPU\n",
        "__global__ void addArrays(int n, float *a, float *b, float *result) {\n",
        "    // Calculate a unique index for each thread\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index < 10){\n",
        "    printf(\"index: %d = %d * %d + %d \\n\", index, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "\n",
        "   // printf(\"bockIdx = %d %d %d \\n\", blockIdx.x, blockIdx.y, blockIdx.z);\n",
        "   // printf(\"blockDim = %d %d %d\\n\", blockDim.x, blockDim.y, blockDim.z);\n",
        "   // printf(\"threadIdx = %d %d %d \\n\", threadIdx.x, threadIdx.y, threadIdx.z);\n",
        "    }\n",
        "    // Check if this thread's index is within the array bounds\n",
        "    if (index < n) {\n",
        "        // This single line of code is executed in parallel by ALL threads\n",
        "        result[index] = a[index] + b[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // 2. SETUP PROBLEM SIZE AND HOST (CPU) MEMORY\n",
        "    int numElements = 1000000;\n",
        "    size_t size = numElements * sizeof(float);\n",
        "\n",
        "    // Allocate and initialize host arrays\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_b = (float *)malloc(size);\n",
        "    float *h_result = (float *)malloc(size); // To store results from GPU\n",
        "\n",
        "    for (int i = 0; i < numElements; i++) {\n",
        "        h_a[i] = 1.0f; // Initialize array a with 1.0\n",
        "        h_b[i] = 2.0f; // Initialize array b with 2.0\n",
        "    }\n",
        "\n",
        "    // 3. ALLOCATE DEVICE (GPU) MEMORY\n",
        "    float *d_a = NULL, *d_b = NULL, *d_result = NULL;\n",
        "    cudaMalloc((void**)&d_a, size);\n",
        "    cudaMalloc((void**)&d_b, size);\n",
        "    cudaMalloc((void**)&d_result, size);\n",
        "\n",
        "    // 4. COPY DATA FROM HOST TO DEVICE\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // 5. CONFIGURE AND LAUNCH THE KERNEL\n",
        "    // Define the execution configuration\n",
        "    int threadsPerBlock = 256; // A common choice\n",
        "    printf(\"threadsPerBlock = %d \\n\", threadsPerBlock);\n",
        "\n",
        "    // Calculate the number of blocks needed to cover the entire array\n",
        "    int blocksPerGrid = (numElements) / threadsPerBlock;\n",
        "    printf(\"blocksPerGrid = %d \\n\", blocksPerGrid);\n",
        "\n",
        "    // Launch the kernel on the GPU\n",
        "    // Syntax: <<<Number of Blocks, Threads per Block>>>\n",
        "    addArrays<<<blocksPerGrid, threadsPerBlock>>>(numElements, d_a, d_b, d_result);\n",
        "\n",
        "    // 6. COPY RESULT BACK FROM DEVICE TO HOST\n",
        "    cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // 7. VERIFY THE RESULTS\n",
        "    // Check the first and last few elements for correctness\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"Element %d: %.1f + %.1f = %.1f (expected 3.0)\\n\",\n",
        "               i, h_a[i], h_b[i], h_result[i]);\n",
        "    }\n",
        "    printf(\"...\\n\");\n",
        "    for (int i = numElements-5; i < numElements; i++) {\n",
        "        printf(\"Element %d: %.1f + %.1f = %.1f (expected 3.0)\\n\",\n",
        "               i, h_a[i], h_b[i], h_result[i]);\n",
        "    }\n",
        "\n",
        "    // 8. FREE ALL ALLOCATED MEMORY\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_result);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_result);\n",
        "\n",
        "    printf(\"Done!\\n\");\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_89 vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "s0jQv6l_2XtI"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm7WXtYT2ugs",
        "outputId": "04a422da-1bee-4777-dbb8-058efaab670a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threadsPerBlock = 256 \n",
            "blocksPerGrid = 3906 \n",
            "index: 0 = 0 * 256 + 0 \n",
            "index: 1 = 0 * 256 + 1 \n",
            "index: 2 = 0 * 256 + 2 \n",
            "index: 3 = 0 * 256 + 3 \n",
            "index: 4 = 0 * 256 + 4 \n",
            "index: 5 = 0 * 256 + 5 \n",
            "index: 6 = 0 * 256 + 6 \n",
            "index: 7 = 0 * 256 + 7 \n",
            "index: 8 = 0 * 256 + 8 \n",
            "index: 9 = 0 * 256 + 9 \n",
            "Element 0: 1.0 + 2.0 = 3.0 (expected 3.0)\n",
            "Element 1: 1.0 + 2.0 = 3.0 (expected 3.0)\n",
            "Element 2: 1.0 + 2.0 = 3.0 (expected 3.0)\n",
            "Element 3: 1.0 + 2.0 = 3.0 (expected 3.0)\n",
            "Element 4: 1.0 + 2.0 = 3.0 (expected 3.0)\n",
            "...\n",
            "Element 999995: 1.0 + 2.0 = 0.0 (expected 3.0)\n",
            "Element 999996: 1.0 + 2.0 = 0.0 (expected 3.0)\n",
            "Element 999997: 1.0 + 2.0 = 0.0 (expected 3.0)\n",
            "Element 999998: 1.0 + 2.0 = 0.0 (expected 3.0)\n",
            "Element 999999: 1.0 + 2.0 = 0.0 (expected 3.0)\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_add.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Kernel definition for matrix addition\n",
        "__global__ void matrixAdd(int N, float* A, float* B, float* C) {\n",
        "    // Calculate row and column indices\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    // Check if within bounds\n",
        "    if (i < N && j < N) {\n",
        "        // Linear index for 1D array representation\n",
        "        int idx = j * N + i;\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1024; // Matrix size (1024x1024)\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    float* h_A = (float*)malloc(size);\n",
        "    float* h_B = (float*)malloc(size);\n",
        "    float* h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialize host matrices\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid dimensions\n",
        "    dim3 threadsPerBlock(16, 16); // 256 threads per block\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixAdd<<<numBlocks, threadsPerBlock>>>(N, d_A, d_B, d_C);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verify result (optional)\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5) {\n",
        "            success = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"Result: \" << (success ? \"PASS\" : \"FAIL\") << std::endl;\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BScglW3z3QVI",
        "outputId": "d8fccbb4-f628-4897-9210-f238e4bbdb11"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_89 matrix_add.cu -o matrix_add"
      ],
      "metadata": {
        "id": "7FbOj53hZcHD"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e59dN4NWZdxa",
        "outputId": "08abb5ee-ffd0-47c3-b76f-941a70494949"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qswR0rE3Zg1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}